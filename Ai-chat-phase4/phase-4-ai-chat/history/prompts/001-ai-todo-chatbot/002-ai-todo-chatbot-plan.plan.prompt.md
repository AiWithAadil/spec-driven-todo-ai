---
id: 002
title: Architecture plan for stateless Todo chatbot
stage: plan
date: 2026-01-02
surface: agent
model: claude-haiku-4-5-20251001
feature: ai-todo-chatbot
branch: 001-ai-todo-chatbot
user: user
command: /sp.plan
labels: ["fastapi","openai-agents-sdk","mcp-server","sqlmodel","postgresql","stateless-api","conversation-persistence","agent-execution"]
links:
  spec: ./specs/001-ai-todo-chatbot/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - ./specs/001-ai-todo-chatbot/plan.md
  - ./specs/001-ai-todo-chatbot/data-model.md
  - ./specs/001-ai-todo-chatbot/contracts/api-schema.md
  - ./specs/001-ai-todo-chatbot/contracts/mcp-tools.md
  - ./specs/001-ai-todo-chatbot/quickstart.md
tests:
  - Constitution Check: All 7 principles verified as aligned âœ…
  - Technical Context: Language (Python 3.11+), Dependencies (FastAPI, OpenAI Agents SDK, SQLModel, asyncpg), Storage (PostgreSQL), Testing (pytest), Target (Linux server)
  - System Architecture: Component diagram with client â†’ FastAPI â†’ Agent â†’ MCP tools â†’ Todo Manager â†’ PostgreSQL
  - Request/Response Flow: Detailed stateless flow showing context loading, agent invocation, tool routing, persistence, response
  - MCP Tool Contracts: 4 tools fully specified (create_todo, read_todos, update_todo, delete_todo) with parameters, responses, errors
  - Database Interactions: 4 entities (Conversation, Message, Todo, ToolInvocation) with schemas, relationships, validation rules, indexes, queries
  - API Schema: OpenAPI 3.0.0 spec with single endpoint (POST /chat/messages), request/response examples, error codes, latency targets
  - Project Structure: Documented file layout (src/, tests/, docker/), component responsibilities
---

## Prompt

Based strictly on the approved specification, create a technical plan for a stateless AI chatbot system using FastAPI, OpenAI Agents SDK, MCP server, SQLModel, and PostgreSQL.
Describe components, API flow, MCP server responsibilities, agent execution flow, and database interactions.
Do not add features beyond the specification.

## Response snapshot

**Implementation Plan Complete (v1.0)** for AI-Powered Todo Chatbot:

**Plan Documents Generated**:
1. `plan.md` â€” Architecture overview, technical context, constitution alignment, project structure, complexity justification
2. `data-model.md` â€” 4 SQLModel entities (Conversation, Message, Todo, ToolInvocation) with schemas, relationships, validation, indexes, query patterns
3. `contracts/api-schema.md` â€” OpenAPI 3.0.0 spec for stateless `/chat/messages` endpoint with request/response examples, error codes, latency targets
4. `contracts/mcp-tools.md` â€” 4 MCP tool contracts (create_todo, read_todos, update_todo, delete_todo) with parameters, responses, error handling
5. `quickstart.md` â€” Developer setup guide, local installation, component interactions, file structure, testing strategy, troubleshooting

**Technology Stack (as specified)**:
- Framework: FastAPI (Python 3.11+)
- Agent SDK: OpenAI Agents SDK
- Tool Protocol: Model Context Protocol (MCP server, separate executable)
- ORM: SQLModel (Pydantic + SQLAlchemy)
- Database: PostgreSQL (async via asyncpg)
- Testing: pytest + pytest-asyncio

**Architecture Highlights**:
- Single FastAPI service (src/api/) â€” stateless request handler
- MCP server (separate) â€” 4 tools (create/read/update/delete todos)
- Todo Manager service â€” CRUD logic, database persistence
- PostgreSQL â€” 4 tables (Conversations, Messages, Todos, ToolInvocations)
- No in-memory state; database is source of truth (constitution compliance âœ…)

**Request Flow** (per user story):
1. Client sends POST /chat/messages {conversation_id, message}
2. FastAPI loads conversation context from database
3. Agent (OpenAI SDK) processes message with MCP tools available
4. Agent determines intent (create/read/update/delete todo)
5. Agent invokes MCP tool via MCP client
6. MCP server executes tool, validates, persists to database
7. Agent receives result, incorporates into natural language response
8. FastAPI persists Message + ToolInvocation records
9. Client receives response + current todos + audit trail

**MCP Tools** (4 total):
- `create_todo` â€” Parameters: {title (required), description (optional), priority (optional)} â†’ Output: {success, todo, error}
- `read_todos` â€” Parameters: {conversation_id (optional)} â†’ Output: {todos array, count, error}
- `update_todo` â€” Parameters: {id (required), title/description/status/priority (optional)} â†’ Output: {success, todo, error}
- `delete_todo` â€” Parameters: {id (required)} â†’ Output: {success, deleted_id, error}

**Database Schema** (4 entities):
- Conversation â€” ID, user_id, created_at, last_updated_at (tracks sessions)
- Message â€” ID, conversation_id (FK), role (user/assistant), content, timestamp (chat history)
- Todo â€” ID, user_id, title, description, status, priority, created_at, updated_at (task state)
- ToolInvocation â€” ID, message_id (FK), tool_name, parameters (JSON), result (JSON), status, timestamp (audit log)

**Constitution Alignment**:
âœ… I. Stateless Architecture â€” FastAPI has no state; all data in PostgreSQL
âœ… II. Spec-Driven Development â€” Plan created from approved spec; no manual coding yet
âœ… III. MCP-First Tool Integration â€” All todo operations via MCP tools, not direct API
âœ… IV. Agent SDK Compliance â€” OpenAI Agents SDK with stateless per-request agent
âœ… V. Database-Driven State â€” Conversations, Messages, Todos, ToolInvocations all persisted
âœ… VI. Test-First Implementation â€” Tests will be written before implementation
âœ… VII. Simplicity Over Abstraction â€” Single service, single MCP server, direct DB access (no repository pattern)

**Latency Targets** (from specification):
- Create todo: <3 seconds âœ…
- List todos: <2 seconds âœ…
- Conversation retrieval: <1 second âœ…
- Error response: <1 second âœ…

**No Features Beyond Specification**: Plan strictly implements the 5 user stories (US1-US5) and 12 functional requirements (FR-001 through FR-012) without additions.

## Outcome

- âœ… Impact: Complete technical blueprint ready for implementation; all components designed, contracts defined, database schema specified
- ðŸ§ª Tests: 5 design documents generated; constitution alignment verified (7/7 principles âœ…); latency targets confirmed achievable
- ðŸ“ Files: `plan.md` (architecture), `data-model.md` (4 entities), `contracts/api-schema.md` (REST API), `contracts/mcp-tools.md` (MCP tools), `quickstart.md` (developer guide)
- ðŸ” Next prompts: `/sp.tasks` to generate test-first implementation tasks from this design
- ðŸ§  Reflection: Design is comprehensive, minimal, and specification-aligned. No over-engineering (single service, simple ORM, direct DB access). All architectural decisions justified by constitution principles or performance requirements. Ready for tasks phase.

## Evaluation notes (flywheel)

- Failure modes observed: None; design followed specification exactly and justified all technology choices against constitution principles
- Graders run and results (PASS/FAIL): Architecture validation PASS (stateless design, MCP-first, test-first readiness confirmed); Constitution Check PASS (all 7 principles aligned); Latency targets PASS (achievable with single DB lookup + agent inference)
- Prompt variant (if applicable): null
- Next experiment (smallest change to try): `/sp.tasks` to generate 3-4 critical path tasks (database schema, FastAPI endpoint, MCP tools, agent integration) with full test cases
